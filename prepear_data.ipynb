{
 "cells": [
  {
   "cell_type": "code",
   "id": "37cb8700-f2f3-4236-ae30-d1103537e468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.678451Z",
     "start_time": "2026-01-19T13:49:08.669522Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from keras import layers\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Flatten, Conv1D\n",
    "# from keras.utils import to_categorical\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import shutil"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.703574Z",
     "start_time": "2026-01-19T13:49:08.694811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DETERMINATIVE_MAP = {\n",
    "    # боги\n",
    "    \"ᴰ\": \"{d}\",\n",
    "\n",
    "    # звёзды\n",
    "    \"ᴹᵁᴸ\": \"{mul}\",\n",
    "\n",
    "    # земля / место\n",
    "    \"ᴷᴵ\": \"{ki}\",\n",
    "\n",
    "    # человек\n",
    "    \"ᴸᵁ₂\": \"{lu₂}\",   # если lu₂ записано с надстрочной ₂\n",
    "    \"ᴸᵁ\": \"{lu₂}\",    # частый OCR-вариант без ₂\n",
    "\n",
    "    # здания\n",
    "    \"ᴱ₂\": \"{e₂}\",\n",
    "    \"ᴱ\": \"{e₂}\",\n",
    "\n",
    "    # населённые пункты\n",
    "    \"ᵁᴿᵁ\": \"{uru}\",\n",
    "\n",
    "    # страны / горы\n",
    "    \"ᴷᵁᴿ\": \"{kur}\",\n",
    "\n",
    "    # женский род\n",
    "    \"ᴹᴵ\": \"{mi}\",\n",
    "\n",
    "    # мужской род\n",
    "    \"ᴹ\": \"{m}\",\n",
    "\n",
    "    # дерево / деревянное\n",
    "    \"ᴳᴵŠ\": \"{geš}\",\n",
    "    \"ᴳᴵŠ\": \"{ĝeš}\",   # при необходимости нормализации\n",
    "\n",
    "    # ткани\n",
    "    \"ᵀᵁᴳ₂\": \"{tug₂}\",\n",
    "    \"ᵀᵁᴳ\": \"{tug₂}\",\n",
    "\n",
    "    # таблички\n",
    "    \"ᴰᵁᴮ\": \"{dub}\",\n",
    "\n",
    "    # река / канал\n",
    "    \"ᴵᴰ₂\": \"{id₂}\",\n",
    "    \"ᴵᴰ\": \"{id₂}\",\n",
    "\n",
    "    # птицы\n",
    "    \"ᴹᵁŠᴱᴺ\": \"{mušen}\",\n",
    "    \"ᴹᵁŠ\": \"{mušen}\",\n",
    "\n",
    "    # камень\n",
    "    \"ᴺᴬ₄\": \"{na₄}\",\n",
    "    \"ᴺᴬ\": \"{na₄}\",\n",
    "\n",
    "    # кожа\n",
    "    \"ᴷᵁŠ\": \"{kuš}\",\n",
    "\n",
    "    # растения\n",
    "    \"ᵁ₂\": \"{u₂}\",\n",
    "    \"ᵁ\": \"{u₂}\",\n",
    "}\n",
    "SUBSCRIPT_DIGITS = str.maketrans({\n",
    "    \"₀\": \"0\",\n",
    "    \"₁\": \"1\",\n",
    "    \"₂\": \"2\",\n",
    "    \"₃\": \"3\",\n",
    "    \"₄\": \"4\",\n",
    "    \"₅\": \"5\",\n",
    "    \"₆\": \"6\",\n",
    "    \"₇\": \"7\",\n",
    "    \"₈\": \"8\",\n",
    "    \"₉\": \"9\",\n",
    "})\n",
    "\n",
    "# --- ASCII → Unicode (фонетическая нормализация)\n",
    "CHAR_MAP = {\n",
    "    's\"': 'š', 'S\"': 'Š',\n",
    "    's,': 'ṣ', 'S,': 'Ṣ',\n",
    "    't,': 'ṭ', 'T,': 'Ṭ',\n",
    "    'h,': 'ḫ', 'H,': 'Ḫ',\n",
    "    \"'\": 'ʾ', \"`\": 'ʿ',\n",
    "    \"’\": 'ʾ', \"‘\": 'ʿ',\n",
    "}\n"
   ],
   "id": "ea3d077f455c6fd2",
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "29a15409-88ca-41b9-8b98-cf72debd788c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.716961Z",
     "start_time": "2026-01-19T13:49:08.712033Z"
    }
   },
   "source": [
    "def extract_quoted_substring(text: str, start_pos: int):\n",
    "    \"\"\"\n",
    "    Ищет в строке text, начиная С позиции start_pos,\n",
    "    подстроку вида: ' \"текст\"'.\n",
    "\n",
    "    Возвращает:\n",
    "        (substring, is_longer_than_30, closing_quote_pos)\n",
    "\n",
    "    Если ничего не найдено — (None, None, None)\n",
    "    \"\"\"\n",
    "    translate = False\n",
    "    open_seq = ' \"'\n",
    "\n",
    "    # поиск начинается С start_pos\n",
    "    open_pos = text.find(open_seq, start_pos)\n",
    "\n",
    "    if open_pos == -1:\n",
    "        return None, None, None\n",
    "\n",
    "    # позиция открывающей кавычки \"\n",
    "    quote_start = open_pos + 1\n",
    "\n",
    "    # ищем закрывающую кавычку \"\n",
    "    quote_end = text.find('\"', quote_start + 1)\n",
    "\n",
    "    if quote_end == -1:\n",
    "        return None, None, None\n",
    "\n",
    "    # подстрока между кавычками\n",
    "    substring = text[quote_start + 1 : quote_end]\n",
    "\n",
    "    if len(substring) > 30:\n",
    "        translate = True\n",
    "         # 1. найти открывающую скобку\n",
    "        open_pos = text.find(\"(\", quote_end)\n",
    "        # if open_pos == -1:\n",
    "        #     return None, None, None\n",
    "        # 2. проверить расстояние от закрывающей кавычки до открывающей скобки\n",
    "        if open_pos - quote_end > 3:\n",
    "            translate = False\n",
    "\n",
    "    return substring, translate, quote_end\n"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "c3a40172-3697-4147-b420-1841061adccc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.739765Z",
     "start_time": "2026-01-19T13:49:08.733395Z"
    }
   },
   "source": [
    "def extract_parenthesized_substring(text: str, start_pos: int):\n",
    "    \"\"\"\n",
    "    С позиции start_pos ищет '('.\n",
    "    Возвращает:\n",
    "        (substring, flag, close_pos)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. найти открывающую скобку\n",
    "    open_pos = text.find(\"(\", start_pos)\n",
    "    if open_pos == -1:\n",
    "        return None, None, None\n",
    "\n",
    "    # 2. проверить расстояние\n",
    "    if open_pos - start_pos > 3:\n",
    "        close_pos_tz = text.find(\";\", open_pos + 1)\n",
    "        # скобка найдена, но слишком далеко\n",
    "        close_pos_s = text.find(\")\", open_pos + 1)\n",
    "        if close_pos_tz != -1 and close_pos_s != -1:\n",
    "            close_pos = min(close_pos_tz, close_pos_s)\n",
    "        else:\n",
    "            if close_pos_tz == -1:\n",
    "                close_pos = close_pos_s\n",
    "            if close_pos_s == -1:\n",
    "                close_pos = close_pos_tz\n",
    "        if close_pos == -1:\n",
    "            return None, None, None\n",
    "        return text[open_pos + 1 : close_pos], False, close_pos\n",
    "\n",
    "    # 3. найти закрывающую скобку\n",
    "    close_pos_tz = text.find(\";\", open_pos + 1)\n",
    "    # скобка найдена, но слишком далеко\n",
    "    close_pos_s = text.find(\")\", open_pos + 1)\n",
    "    if close_pos_tz != -1 and close_pos_s != -1:\n",
    "        close_pos = min(close_pos_tz, close_pos_s)\n",
    "    else:\n",
    "        if close_pos_tz == -1:\n",
    "            close_pos = close_pos_s\n",
    "        if close_pos_s == -1:\n",
    "            close_pos = close_pos_tz\n",
    "    if close_pos == -1:\n",
    "        return None, None, None\n",
    "\n",
    "    substring = text[open_pos + 1 : close_pos]\n",
    "\n",
    "    # 4. условия\n",
    "    is_long = len(substring) > 30\n",
    "    dash_count = substring.count(\"-\")\n",
    "\n",
    "    flag = is_long and dash_count >= 6\n",
    "\n",
    "    return substring, flag, close_pos\n"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.755839Z",
     "start_time": "2026-01-19T13:49:08.748844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_letter_space_digit_colon_space(text: str, start_search_pos: int):\n",
    "    # 1. Основной шаблон\n",
    "    pattern = re.compile(\n",
    "        r'[A-Za-z]{3,5} \\d{4}: \\d{2,}'\n",
    "    )\n",
    "\n",
    "    match = pattern.search(text, start_search_pos)\n",
    "    if not match:\n",
    "        return None, None, None\n",
    "\n",
    "    # 2. Проверка 5 символов после группы\n",
    "    pos = match.end()\n",
    "    limit = min(pos + 5, len(text))\n",
    "\n",
    "    start_pos = pos\n",
    "    for i in range(pos, limit):\n",
    "        if text[i].isdigit() or text[i] == '-':\n",
    "            start_pos = i + 1\n",
    "        else:\n",
    "            start_pos = i\n",
    "            break\n",
    "\n",
    "    # 3. Поиск одинарной открывающей кавычки\n",
    "    quote_pos = text.find(\"'\", start_pos)\n",
    "    if quote_pos == -1:\n",
    "        return None, None, None\n",
    "\n",
    "    diff = quote_pos - start_pos\n",
    "    if diff >= 1000:\n",
    "        return None, None, None\n",
    "\n",
    "    # 4. Проверка подстроки\n",
    "    substr = text[start_pos:quote_pos]\n",
    "\n",
    "    dash_count = substr.count('-')\n",
    "    aleph_count = substr.count('ℵ')\n",
    "\n",
    "    dash_required = diff / 10.5\n",
    "\n",
    "    if dash_count >= dash_required or aleph_count >= 2:\n",
    "        transliter_txt = substr\n",
    "        return transliter_txt, True, quote_pos - 1\n",
    "\n",
    "    return None, None, None\n"
   ],
   "id": "8f8cfa2587e20323",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.767810Z",
     "start_time": "2026-01-19T13:49:08.763871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_single_quotes(text: str, start_pos: int):\n",
    "    if start_pos < 0 or start_pos >= len(text):\n",
    "        return None, None, None\n",
    "\n",
    "    # 1. Поиск закрывающей одинарной кавычки\n",
    "    quote_pos = text.find(\"'\", start_pos)\n",
    "    if quote_pos == -1:\n",
    "        return None, None, None\n",
    "\n",
    "    # 2. Проверка расстояния\n",
    "    if quote_pos - start_pos > 1200:\n",
    "        return None, None, None\n",
    "\n",
    "    # 3. Извлечение подстроки\n",
    "    translate_txt = text[start_pos:quote_pos]\n",
    "\n",
    "    # 4. Возврат результата\n",
    "    return translate_txt, True, quote_pos - 1\n"
   ],
   "id": "deb38fce8778ed62",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.779949Z",
     "start_time": "2026-01-19T13:49:08.774845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_akkadian_determinatives(text: str) -> str:\n",
    "    for sup, norm in DETERMINATIVE_MAP.items():\n",
    "        text = text.replace(sup, norm)\n",
    "    return text\n"
   ],
   "id": "b5269ef7d02e81ee",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.791791Z",
     "start_time": "2026-01-19T13:49:08.787268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_subscripts(text: str) -> str:\n",
    "    return text.translate(SUBSCRIPT_DIGITS)\n"
   ],
   "id": "9f17def3541cf421",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.802016Z",
     "start_time": "2026-01-19T13:49:08.798380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_gaps(text: str) -> str:\n",
    "    # порядок замен важен!\n",
    "    replacements = [\n",
    "        (r\"\\[\\s*…\\s*…\\s*\\]\", \"<big_gap>\"),  # [… …]\n",
    "        (r\"\\[x\\]\", \"<gap>\"),               # [x]\n",
    "        (r\"…\", \"<big_gap>\"),               # …\n",
    "    ]\n",
    "\n",
    "    for pattern, repl in replacements:\n",
    "        text = re.sub(pattern, repl, text)\n",
    "\n",
    "    return text\n"
   ],
   "id": "6280ccd4145dbf28",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.811795Z",
     "start_time": "2026-01-19T13:49:08.808389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def normalize_assyrian_line(text: str) -> str:\n",
    "#     # 1. Удаляем редакторскую метку Pl-/\n",
    "#     text = re.sub(r\"^Pl-/\\s*\", \"\", text)\n",
    "#\n",
    "#     # 2. Удаляем перенос строки (\\)\n",
    "#     text = text.replace(\"\\\\\", \"\")\n",
    "#\n",
    "#     # 3. Удаляем запятую (маркер переноса строки)\n",
    "#     text = text.replace(\",\", \"\")\n",
    "#\n",
    "#     # 4. Обрабатываем квадратные скобки\n",
    "#     def replace_supplied(match):\n",
    "#         content = match.group(1).strip()\n",
    "#\n",
    "#         # лакуны — не трогаем\n",
    "#         if content == \"x\":\n",
    "#             return \"[x]\"\n",
    "#         if re.fullmatch(r\"[.\\s…]+\", content):\n",
    "#             return f\"[{content}]\"\n",
    "#\n",
    "#         # восстановленный текст → склеиваем\n",
    "#         return \"-\" + content\n",
    "#\n",
    "#     text = re.sub(r\"\\[([^\\]]+)\\]\", replace_supplied, text)\n",
    "#\n",
    "#     # 5. Убираем лишние пробелы\n",
    "#     text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "#\n",
    "#     return text\n"
   ],
   "id": "b37ba4dc2eec1c21",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.824359Z",
     "start_time": "2026-01-19T13:49:08.817958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_for_mt(text: str) -> str:\n",
    "    # 0. Базовая очистка (translate-таблица уже применяется снаружи)\n",
    "    a = text\n",
    "    chars_to_remove = \"!?/:.<>˹˺[]ℵ⅀⅁\"\n",
    "    table = str.maketrans(\"\", \"\", chars_to_remove)\n",
    "    # 1. ASCII → Unicode\n",
    "    for old, new in CHAR_MAP.items():\n",
    "        a = a.replace(old, new)\n",
    "\n",
    "    # удаление ненужных символов\n",
    "    a = a.translate(table)\n",
    "\n",
    "    # 2. Надстрочные детерминативы\n",
    "    a = normalize_akkadian_determinatives(a)\n",
    "\n",
    "    # 3. Подстрочные цифры\n",
    "    a = normalize_subscripts(a)\n",
    "\n",
    "    # 4. Удаляем редакторские маркеры\n",
    "    a = re.sub(r\"^Pl-/\\s*\", \"\", a)   # Pl-/\n",
    "    a = a.replace(\"\\\\\", \"\")          # перенос строки\n",
    "    a = a.replace(\",\", \"\")           # маркер переноса строки\n",
    "\n",
    "    # 5. Квадратные скобки: восстановление vs лакуны\n",
    "    def handle_brackets(match):\n",
    "        content = match.group(1).strip()\n",
    "\n",
    "        # лакуны\n",
    "        if content == \"x\":\n",
    "            return \"<gap>\"\n",
    "        if re.fullmatch(r\"[.…\\s]+\", content):\n",
    "            return \"<big_gap>\"\n",
    "\n",
    "        # восстановленный текст → включаем в слово\n",
    "        return \"-\" + content\n",
    "\n",
    "    a = re.sub(r\"\\[([^\\]]+)\\]\", handle_brackets, a)\n",
    "\n",
    "    # 6. Финальная нормализация пробелов\n",
    "    a = re.sub(r\"\\s+\", \" \", a).strip()\n",
    "\n",
    "    return a\n"
   ],
   "id": "b74dbb9ff8926504",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.844290Z",
     "start_time": "2026-01-19T13:49:08.835177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def align_and_mark_sentences(translit_text: str, translation_sentences: list, marker=\"<sent>\") -> str:\n",
    "    \"\"\"\n",
    "    Точная выравнивающая функция для вставки маркеров конца предложений в транслитерацию.\n",
    "\n",
    "    Args:\n",
    "        translit_text: Нормализованная транслитерация (str)\n",
    "        translation_sentences: Список английских предложений (list of str)\n",
    "        marker: Спец-токен конца предложения (default \"<sent>\")\n",
    "\n",
    "    Returns:\n",
    "        Строка транслитерации с маркерами конца предложений\n",
    "    \"\"\"\n",
    "    translit_tokens = translit_text.split()\n",
    "    translation_lengths = [len(sent.split()) for sent in translation_sentences]\n",
    "    total_translit = len(translit_tokens)\n",
    "    total_translation = sum(translation_lengths)\n",
    "\n",
    "    # Вычисляем пропорцию токенов транслитерации на токен перевода\n",
    "    tokens_per_translation_token = total_translit / total_translation\n",
    "\n",
    "    marked_tokens = []\n",
    "    idx = 0\n",
    "\n",
    "    for length in translation_lengths:\n",
    "        # Сколько токенов транслитерации примерно для этого предложения\n",
    "        num_tokens = max(1, round(length * tokens_per_translation_token))\n",
    "        sent_tokens = translit_tokens[idx: idx + num_tokens]\n",
    "        marked_tokens.extend(sent_tokens)\n",
    "        marked_tokens.append(marker)\n",
    "        idx += num_tokens\n",
    "\n",
    "    # Добавляем остаток токенов, если есть\n",
    "    if idx < total_translit:\n",
    "        marked_tokens.extend(translit_tokens[idx:])\n",
    "        marked_tokens.append(marker)\n",
    "\n",
    "    return \" \".join(marked_tokens)\n"
   ],
   "id": "b773cf41846a0e4a",
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "c83c9f51-f1ef-43ee-b6a9-0dd5f18f9580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.862286Z",
     "start_time": "2026-01-19T13:49:08.852666Z"
    }
   },
   "source": [
    "\n",
    "def process_text_and_build_csv_rows(text: str):\n",
    "    \"\"\"\n",
    "    Обрабатывает текст и возвращает список строк CSV\n",
    "    (без заголовка)\n",
    "    \"\"\"\n",
    "    csv_rows = []\n",
    "    start_pos = 0\n",
    "\n",
    "    while start_pos < len(text):\n",
    "        # поиск по двойным кавычкам\n",
    "        translate_str, flag, next_pos = extract_quoted_substring(text, start_pos)\n",
    "        # if translate_str is None:\n",
    "        #     break\n",
    "\n",
    "        if flag:\n",
    "            # print(translate_str)\n",
    "            # поиск по круглым скобкам\n",
    "            accad_str, flag2, close_pos = extract_parenthesized_substring(\n",
    "                text, next_pos)\n",
    "\n",
    "            if flag2:\n",
    "                # 1. Очистка перевода\n",
    "                t = translate_str.replace(\"\\n\", \" \")\n",
    "\n",
    "                # 2. Очистка аккадского\n",
    "                a = accad_str.replace(\"\\n\", \" \")\n",
    "                a = normalize_for_mt(a)\n",
    "\n",
    "                # 3. Токенизация перевода\n",
    "                t_sentences = sent_tokenize(t)\n",
    "\n",
    "                # 4. Выравнивание + маркеры\n",
    "                a = align_and_mark_sentences(a, t_sentences, marker=\"<sent>\")\n",
    "\n",
    "                # 5. Склеиваем перевод обратно\n",
    "                t = \" \".join(t_sentences)\n",
    "\n",
    "                # 6. CSV-экранирование (ОДИН РАЗ!)\n",
    "                a = a.replace('\"', '\"\"')\n",
    "                t = t.replace('\"', '\"\"')\n",
    "\n",
    "                csv_rows.append(f'\"{a}\",\"{t}\"\\n')\n",
    "                start_pos = close_pos + 1\n",
    "            else:\n",
    "                start_pos = next_pos + 1\n",
    "        elif flag == False:\n",
    "            start_pos = next_pos + 1\n",
    "        else:\n",
    "            # поиск по буквам пробел цифрам двоеточию пробелу цифрам\n",
    "            accad_str, flag3, next_pos = extract_letter_space_digit_colon_space(text, start_pos)\n",
    "            if flag3:\n",
    "                # поиск по одинарным кавычкам\n",
    "                translate_str, flag4, close_pos = extract_parenthesized_substring(text, next_pos)\n",
    "                if flag4:\n",
    "                    # 1. Очистка перевода\n",
    "                    t = translate_str.replace(\"\\n\", \" \")\n",
    "\n",
    "                    # 2. Очистка аккадского\n",
    "                    a = accad_str.replace(\"\\n\", \" \")\n",
    "                    a = normalize_for_mt(a)\n",
    "\n",
    "                    # 3. Токенизация перевода\n",
    "                    t_sentences = sent_tokenize(t)\n",
    "\n",
    "                    # 4. Выравнивание + маркеры\n",
    "                    a = align_and_mark_sentences(a, t_sentences, marker=\"<sent>\")\n",
    "\n",
    "                    # 5. Склеиваем перевод обратно\n",
    "                    t = \" \".join(t_sentences)\n",
    "\n",
    "                    # 6. CSV-экранирование (ОДИН РАЗ!)\n",
    "                    a = a.replace('\"', '\"\"')\n",
    "                    t = t.replace('\"', '\"\"')\n",
    "\n",
    "                    csv_rows.append(f'\"{a}\",\"{t}\"\\n')\n",
    "                    start_pos = close_pos + 1\n",
    "            else:\n",
    "                start_pos = next_pos + 1\n",
    "    return csv_rows\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.878393Z",
     "start_time": "2026-01-19T13:49:08.872614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------------\n",
    "# Функция разбивки перевода на предложения\n",
    "# ----------------------------\n",
    "def naive_sent_tokenize(text):\n",
    "    \"\"\"\n",
    "    Разделяет текст на предложения по точкам, восклицательным и вопросительным знакам.\n",
    "    Работает для английского перевода.\n",
    "    \"\"\"\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    return [s.strip() for s in sentences if s.strip()]"
   ],
   "id": "7835b6755964f65a",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.890037Z",
     "start_time": "2026-01-19T13:49:08.884636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "def parse_csv_line(line: str):\n",
    "    reader = csv.reader(StringIO(line))\n",
    "    accad_str, translate_str = next(reader)\n",
    "    return accad_str, translate_str"
   ],
   "id": "36abe1990b201a11",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.903644Z",
     "start_time": "2026-01-19T13:49:08.897623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------------\n",
    "# Выравнивание и разбивка транслитерации по <sent>\n",
    "# ----------------------------\n",
    "def split_accad_and_translate(csv_lines, marker=\"<sent>\"):\n",
    "    rows = []\n",
    "    global_id = 0\n",
    "\n",
    "    for line in csv_lines:\n",
    "        accad_str, translate_str = parse_csv_line(line)\n",
    "\n",
    "        accad_sentences = [s.strip() for s in accad_str.split(marker) if s.strip()]\n",
    "        translate_sentences = naive_sent_tokenize(translate_str)\n",
    "\n",
    "        min_len = min(len(accad_sentences), len(translate_sentences))\n",
    "        accad_sentences = accad_sentences[:min_len]\n",
    "        translate_sentences = translate_sentences[:min_len]\n",
    "\n",
    "        for accad, trans in zip(accad_sentences, translate_sentences):\n",
    "            rows.append({\n",
    "                \"id\": global_id,\n",
    "                \"accad_str\": accad,\n",
    "                \"translate\": trans\n",
    "            })\n",
    "            global_id += 1\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"id\", \"accad_str\", \"translate\"])\n"
   ],
   "id": "5f16b2b8b713ffbf",
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "id": "7dce5f87-7997-4b52-a849-c8718b3c5c39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:49:08.914940Z",
     "start_time": "2026-01-19T13:49:08.910275Z"
    }
   },
   "source": [
    "def print_file_head(path, n=5, encoding=\"utf-8\"):\n",
    "    with open(path, \"r\", encoding=encoding) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= n:\n",
    "                break\n",
    "            print(f\"{i}: {line.rstrip()}\")\n"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "id": "afeb81e9-9ae9-44ba-a37e-297671183a85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:50:04.238006Z",
     "start_time": "2026-01-19T13:49:15.882048Z"
    }
   },
   "source": [
    "# Завантаження даних з CSV-файлу\n",
    "# thiscompteca = \"D:/Projects/Python/Конкурсы/Old_accad_translate/\"\n",
    "thiscompteca = \"G:/Visual Studio 2010/Projects/Python/Old_accad_translate/\"\n",
    "csv_file_path = thiscompteca+'/data/publications.csv'\n",
    "df_trnl = pd.read_csv(csv_file_path)\n",
    "\n",
    "# print(df_trnl[df_trnl['has_akkadian']].head(20))  # Перші 5 строк даних\n",
    "# print(df_trnl.shape)  # Dataset Shape\n",
    "# print(df_trnl.info())  # Dataset Information\n",
    "# print(df_trnl.describe())   # Statistics\n",
    "# print(df_trnl.isnull().sum())  # Missing Values\n",
    "print('\\n')\n",
    "\n",
    "# idx = df_trnl[df_trnl['has_akkadian']].head(3).index\n",
    "idx = df_trnl[df_trnl['has_akkadian']].index\n",
    "df_trnl.loc[idx, df_trnl.columns[2]] = (\n",
    "    df_trnl.loc[idx, df_trnl.columns[2]]\n",
    "    .str.replace(\"\\\\n\", \"\\n\", regex=False)\n",
    ")\n",
    "num = 0\n",
    "all_rows = []\n",
    "for i in idx:\n",
    "    # print(f\"index = {i}\")\n",
    "    # print(\"Назва файлу:\", df_trnl.iat[i, 0])\n",
    "    # print(\"Сторінка з текстом, що містить переклад:\", df_trnl.iat[i, 1])\n",
    "    # print(\"Текст всієї статті:\\n\", df_trnl.iat[i, 2])\n",
    "    # print(\"-\" * 50)\n",
    "    list_row = []\n",
    "    list_row = process_text_and_build_csv_rows(df_trnl.iat[i, 2])\n",
    "    all_rows.extend(list_row)\n",
    "    num += 1\n",
    "\n",
    "# for i in idx[:10]:  # первые 10 для проверки\n",
    "#     text = df_trnl.iat[i, 2]\n",
    "#     rows = process_text_and_build_csv_rows(text)\n",
    "#     print(f\"Строка {i}: найдено {len(rows)} фрагментов\")\n",
    "\n",
    "\n",
    "\n",
    "new_df = split_accad_and_translate(all_rows)\n",
    "new_df.to_csv('translate_from_publication.csv', index=False)\n",
    "print(\"Примеры строк:\")\n",
    "print(new_df)\n",
    "print(len(idx))\n",
    "# print(num)\n",
    "print('\\n')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"G:\\Program Files\\JetBrains\\PyCharm 2025.2\\plugins\\python-ce\\helpers\\pydev\\_pydevd_bundle\\pydevd_comm.py\", line 736, in make_thread_stack_str\n",
      "    append('file=\"%s\" line=\"%s\">' % (make_valid_xml_value(my_file), lineno))\n",
      "                                     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"G:\\Program Files\\JetBrains\\PyCharm 2025.2\\plugins\\python-ce\\helpers\\pydev\\_pydevd_bundle\\pydevd_xml.py\", line 36, in make_valid_xml_value\n",
      "    return s.replace(\"&\", \"&amp;\").replace('<', '&lt;').replace('>', '&gt;').replace('\"', '&quot;')\n",
      "           ^^^^^^^^^\n",
      "AttributeError: 'tuple' object has no attribute 'replace'\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "id": "ae6ef44b-2c32-4305-ad3b-3353447b063f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:24:06.629817900Z",
     "start_time": "2026-01-18T18:45:52.522931Z"
    }
   },
   "source": [
    "# Завантаження даних з CSV-файлу\n",
    "# thiscompteca = \"C:/Users/arecs/Мій диск (2armnot@gmail.com)/Питон/Конкурси/Old_Assyrian/\"\n",
    "csv_file_path = thiscompteca+'/data/published_texts.csv'\n",
    "df_txt = pd.read_csv(csv_file_path)\n",
    "num_row = 0\n",
    "for num_row in range(df_txt.shape[0]):\n",
    "    if num_row > 3:\n",
    "        break\n",
    "    for num_col in range(df_txt.shape[1]):\n",
    "        print(df_txt.iat[num_row, num_col])\n",
    "    print('-' * 50)\n",
    "\n",
    "# print(df_txt.head())  # Перші 5 строк даних\n",
    "# print(df_txt.shape)  # Dataset Shape\n",
    "# print(df_txt.info())  # Dataset Information\n",
    "# print(df_txt.describe())   # Statistics\n",
    "# print(df_txt.isnull().sum())  # Missing Values"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bd4b7138-70d5-490d-8234-299b0a75d3a3\n",
      "https://oare.byu.edu/epigraphies/bd4b7138-70d5-490d-8234-299b0a75d3a3\n",
      "P361099\n",
      "MP 1 bis\n",
      "Cuneiform Tablet RA 60 125\n",
      "RA 60 125\n",
      "Cuneiform envelope, dated to the Old Assyrian Period (ca. 1950-1850 BC).\n",
      "letter\n",
      "MP 1 bis\n",
      "nan\n",
      "Collection: MP 1 bis\n",
      "P. Garelli RA 60 S. 124-125; Michel Innaya II, 214 #10 Hüllenfrgt.\n",
      "nan\n",
      "nan\n",
      "4395\n",
      "nan\n",
      "https://aicuneiform.com/search?q=P361099\n",
      "KIŠIB a-šùr-ma-lik DUMU i-na-a a-na a-šùr-na-da DUMU … ù en-um-a-šùr DUMU … a-pu-tum a-na a-wa-at ṭup-pì-im iḫ-da … ša ú-… ḫa-sí-sú …\n",
      "KIŠIB a-šùr-ma-lik DUMU i-na-a a-na a-šùr-na-da DUMU <big_gap> ù en-um-a-šùr DUMU <big_gap> a-pu-tum a-na a-wa-at ṭup-pì-im iḫ-da <big_gap> ša ú-<big_gap> ḫa-sí-sú <big_gap>\n",
      "--------------------------------------------------\n",
      "b05376c2-fc3d-49f8-9792-a25c0df9c383\n",
      "https://oare.byu.edu/epigraphies/b05376c2-fc3d-49f8-9792-a25c0df9c383\n",
      "P359543\n",
      "ICK 1 146\n",
      "Cuneiform Tablet ICK 1 146\n",
      "Ka 185 | Ka 455 | Ka 424?\n",
      "Cuneiform tablet, dated to the Old Assyrian Period (ca. 1950-1850 BC).\n",
      "debt note\n",
      "Ist Ka 185 | Ist Ka 455 | Ist Ka 424?\n",
      "nan\n",
      "ICK 1, 146 & ICK 2, 33 (env) + ICK 2, 163 (env)\n",
      "Ichisar, Imdilum 65f.\n",
      "nan\n",
      "nan\n",
      "1888\n",
      "nan\n",
      "https://aicuneiform.com/search?q=P359543\n",
      "0.33333 ma-na 7 GÍN KÙ.BABBAR ṣa-ru-pá-am i-ṣé-er en-na-nim im-dí-lu-um i-šu iš-tù ḫa-mu-uš-tim ša šu-be-lim DUMU a-na-lí a-na 8 ḫa-am-ša-tim i-ša-qal šu-ma i-na u₄-me-šu ma-al-ú-tim lá iš-qú-ul ki-ma a-wa-at kà-ri-im ú-ṣa-áb IGI en-nam-a-šur\n",
      "0.33333 ma-na 7 GÍN KÙ.BABBAR ṣa-ru-pá-am i-ṣé-er en-na-nim im-dí-lu-um i-šu iš-tù ḫa-mu-uš-tim ša šu-be-lim DUMU a-na-lí a-na 8 ḫa-am-ša-tim i-ša-qal šu-ma i-na u₄-me-šu ma-al-ú-tim lá iš-qú-ul ki-ma a-wa-at kà-ri-im ú-ṣa-áb IGI en-nam-a-šur\n",
      "--------------------------------------------------\n",
      "80547963-f2a2-4d5d-9544-fc7ada60d3b2\n",
      "https://oare.byu.edu/epigraphies/80547963-f2a2-4d5d-9544-fc7ada60d3b2\n",
      "P361681\n",
      "TrMA 1 | Or 36 396 n. 2\n",
      "Cuneiform Tablet Or 36 396A.2\n",
      "nan\n",
      "Cuneiform tablet, dated to the Old Assyrian Period (ca. 1950-1850 BC).\n",
      "debt note\n",
      "TrMA 1\n",
      "nan\n",
      "Or 36 396 n. 2\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "56\n",
      "nan\n",
      "https://aicuneiform.com/search?q=P361681\n",
      "{large break} a-na a-lá-lá-ma-sí ù a-mur-DINGIR qí-bi₄-ma šu-ma KÙ.BABBAR ša-ḫa-tám lá i-mu-a-ma lu-qú-tám lá ú-šar 8 ma-na KÙ.BABBAR a-na ṣí-ib-tim le-qé-a-nim ù pì-lá-aḫ-a-šur qá-sú li-dí-ma 15 ma-na KÙ.BABBAR ni-is-ḫa-sú DIRI ša-du-a-sú ša-bu ku-un-kà-ma a-na a-lim{ki} šé-bi-lá-ma ma-lá pì-lá-aḫ-a-šur ší-ma-am i-qá-bi₄-ú ṭup-pá-am iš-tí-šu lá-pì-ta šu-ma lá ta-qí-pá qá-tí ma-aḫ-ṣa-ma a-dí KÙ.BABBAR ú-šé-ba-lá-ni kà-i-lá a-ḫu-a a-tù-nu-ma iḫ-da-ma li-bi₄ pì-lá-aḫ-a-šur lá i-ma-ra-aṣ\n",
      "<big_gap> a-na a-lá-lá-ma-sí ù a-mur-DINGIR qí-bi₄-ma šu-ma KÙ.BABBAR ša-ḫa-tám lá i-mu-a-ma lu-qú-tám lá ú-šar 8 ma-na KÙ.BABBAR a-na ṣí-ib-tim le-qé-a-nim ù pì-lá-aḫ-a-šur qá-sú li-dí-ma 15 ma-na KÙ.BABBAR ni-is-ḫa-sú DIRI ša-du-a-sú ša-bu ku-un-kà-ma a-na a-lim{ki} šé-bi-lá-ma ma-lá pì-lá-aḫ-a-šur ší-ma-am i-qá-bi₄-ú ṭup-pá-am iš-tí-šu lá-pì-ta šu-ma lá ta-qí-pá qá-tí ma-aḫ-ṣa-ma a-dí KÙ.BABBAR ú-šé-ba-lá-ni kà-i-lá a-ḫu-a a-tù-nu-ma iḫ-da-ma li-bi₄ pì-lá-aḫ-a-šur lá i-ma-ra-aṣ\n",
      "--------------------------------------------------\n",
      "8c0d4238-f795-4061-8b3c-8469a66d86d6\n",
      "https://oare.byu.edu/epigraphies/8c0d4238-f795-4061-8b3c-8469a66d86d6\n",
      "P361098\n",
      "MP 1\n",
      "Cuneiform Tablet RA 60 123\n",
      "RA 60 123\n",
      "Cuneiform tablet, dated to the Old Assyrian Period (ca. 1950-1850 BC).\n",
      "letter\n",
      "MP 1\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "4394\n",
      "nan\n",
      "https://aicuneiform.com/search?q=P361098\n",
      "um-ma PUZUR₄-a-šùr-ma a-na bu-za-zu qí-bi-ma a-šu-mì DUB ša 45 GÚ URUDU ša ta-áš-pu-ra-ni i-nu-mì ta-ta-al-ku-ma iš-tí-kà ú-ṣa-ni um-ma a-ta-ma ṭup-pá-am šu-a-tí dí-na-šu pá-i a-dí-na-kum um-ma a-na-ku-ma le-qé-šu a-lá-ak-ma i li-bi₄ ṭup-pì-kà a-ša-kà-šu wa-ar-ki-tám-ma áš-pu-ra-kum um-ma a-na-ku-ma a-ḫi a-ta a-na ṭup-pì-im lá ta-da-ga-al x a-ma-kam wa-ša-áb a-pu-tum i-ḫi-id-ma KÙ.BABBAR-ap-kà a-wi-lam ša-áš-qí-il₅ šu-ma KÙ.BABBAR lá i-ta-ad-na-kum ṭup-pu-um ku-a-tí i-za-za-kum a-ta KÙ.BABBAR té-ri-iš lá té-ri-iš a-na ṭup-pì-im ta-áš-tap-ra-am ù 3 ṣa-ba-am a-na ší-bu-tim iš-tí-a tal-ta-ap-tám i-na mì-nim ṭup-pu-um a ku-a-im i-tur₄ a-na-ku a-na KÙ.BABBAR ša qá-ta-at šu-IŠTAR a-na be-lúm-ba-ni al-ta-ap-tù KÙ.BABBAR a bu-ru-uš-ḫa-dum i-a-tí i-lá-ak a KÙ.BABBAR ta-ap-x-x-ma um-ma a-na-ku-ma li-dí-na la x ma x am\n",
      "um-ma PUZUR₄-a-šùr-ma a-na bu-za-zu qí-bi-ma a-šu-mì DUB ša 45 GÚ URUDU ša ta-áš-pu-ra-ni i-nu-mì ta-ta-al-ku-ma iš-tí-kà ú-ṣa-ni um-ma a-ta-ma ṭup-pá-am šu-a-tí dí-na-šu pá-i a-dí-na-kum um-ma a-na-ku-ma le-qé-šu a-lá-ak-ma i li-bi₄ ṭup-pì-kà a-ša-kà-šu wa-ar-ki-tám-ma áš-pu-ra-kum um-ma a-na-ku-ma a-ḫi a-ta a-na ṭup-pì-im lá ta-da-ga-al <gap> a-ma-kam wa-ša-áb a-pu-tum i-ḫi-id-ma KÙ.BABBAR-ap-kà a-wi-lam ša-áš-qí-il₅ šu-ma KÙ.BABBAR lá i-ta-ad-na-kum ṭup-pu-um ku-a-tí i-za-za-kum a-ta KÙ.BABBAR té-ri-iš lá té-ri-iš a-na ṭup-pì-im ta-áš-tap-ra-am ù 3 ṣa-ba-am a-na ší-bu-tim iš-tí-a tal-ta-ap-tám i-na mì-nim ṭup-pu-um a ku-a-im i-tur₄ a-na-ku a-na KÙ.BABBAR ša qá-ta-at šu-IŠTAR a-na be-lúm-ba-ni al-ta-ap-tù KÙ.BABBAR a bu-ru-uš-ḫa-dum i-a-tí i-lá-ak a KÙ.BABBAR ta-ap-<gap>-<gap>-ma um-ma a-na-ku-ma li-dí-na la <gap> ma <gap> am\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 161
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ed601c-ee48-4cea-81fd-85d8c69ce8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878 entries, 0 to 877\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   pdf_name      878 non-null    object\n",
      " 1   title         871 non-null    object\n",
      " 2   author        846 non-null    object\n",
      " 3   author_place  544 non-null    object\n",
      " 4   journal       583 non-null    object\n",
      " 5   volume        568 non-null    object\n",
      " 6   year          878 non-null    object\n",
      " 7   pages         533 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 55.0+ KB\n",
      "None\n",
      "(OCR) JCS 59, 2007, pp. 93-106 - Larsen, Mogens T. - Individual and Family in Old Assyrian Society.pdf\n",
      "Individual and Family in Old Assyrian Society\n",
      "Mogens Trolle Larsen\n",
      "Copenhagen\n",
      "JCS\n",
      "59\n",
      "2007\n",
      "93–95\n",
      "--------------------------------------------------\n",
      "AKT 6a.pdf\n",
      "The Archive of the Salim-Assur Family\n",
      "Mogens Trolle Larsen\n",
      "Ankara\n",
      "Turk Tarih Kurumu Yayınları\n",
      "VI. Dizi- Sayı 33 d-a\n",
      "2010\n",
      "xvi, 585 s.\n",
      "--------------------------------------------------\n",
      "AKT 6b.pdf\n",
      "Kiiltepe tabletleri VI-b: The Archive of the Salim-Assur family. Volume 2: Ennam- Assur\n",
      "Mogens Trolle Larsen\n",
      "Ankara\n",
      "Turk Tarih Kurumu\n",
      "nan\n",
      "2013\n",
      "xvii, 470 s.\n",
      "--------------------------------------------------\n",
      "AKT 6c.pdf\n",
      "Küiltepe Tabletleri VI-c: The Archive of the Salim-Assur Family: Volume 3: Ali-ahum\n",
      "Mogens Trolle Larsen\n",
      "Ankara\n",
      "Turk Tarih Kurumu Yayınları\n",
      "VI. Dizi - Sayı 33d-c\n",
      "2014\n",
      "396\n",
      "--------------------------------------------------\n",
      "AKT 6d.pdf\n",
      "Killtepe tabletleri VI-d: the archive of the Salim-Assur family. Volume 4, Texts concerning non-family members\n",
      "Mogens Trolle Larsen\n",
      "Ankara\n",
      "Turk Tarih Kurumu\n",
      "4\n",
      "2018\n",
      "xv, 246 s.\n",
      "--------------------------------------------------\n",
      "AKT 6e.pdf\n",
      "Kultepe tabletleri VI-e: the archive of the Salim-Assur family. Volume 5, Anonymous texts and fragments\n",
      "Mogens Trolle Larsen\n",
      "Ankara\n",
      "Turk Tarih Kurumu Yayınları\n",
      "VI. Dizi - Say1: 33d-e\n",
      "2021\n",
      "xv, 446 s.\n",
      "--------------------------------------------------\n",
      "Larsen 1967 - Old Assyrian Caravan Procedures. PIHANS 22, 1967.pdf\n",
      "Old Assyrian Caravan Procedures\n",
      "Mogens Trolle Larsen\n",
      "Istanbul\n",
      "Nederlands Historisch-Archaeologisch Instituut\n",
      "XXII\n",
      "1967\n",
      "179\n",
      "--------------------------------------------------\n",
      "Larsen 1979 - Power and Propaganda. Mesopotamia 7, 1979.pdf\n",
      "Power and Propaganda: A Symposium on Ancient Empires\n",
      "Mogens Trolle Larsen\n",
      "Copenhagen\n",
      "Copenhagen Studies in Assyriology\n",
      "7\n",
      "1979\n",
      "7–361\n",
      "--------------------------------------------------\n",
      "Larsen 1982 - Your Money or Your Life. A Portrait of an Assyrian Businessman. FS Diakonoff, 1982 214-245.pdf\n",
      "YOUR MONEY OR YOUR LIFE! A PORTRAIT OF AN ASSYRIAN BUSINESSMAN\n",
      "Mogens Trolle Larsen\n",
      "Copenhagen\n",
      "nan\n",
      "nan\n",
      "1982\n",
      "215\n",
      "--------------------------------------------------\n",
      "Larsen 1987 - Commercial networks in the Ancient Near East, Ch. 5. CPAW 1987 pp. 47-56.pdf\n",
      "Commercial networks in the Ancient Near East\n",
      "Mogens Trolle Larsen\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1987\n",
      "nan\n",
      "--------------------------------------------------\n",
      "Larsen 1995 - Introduction, literacy and social complexity. State and Society 1995 pp. 173-190.pdf\n",
      "Literacy and social complexity\n",
      "Mogens Trolle Larsen\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1995\n",
      "nan\n",
      "--------------------------------------------------\n",
      "Larsen 2000 - The City-States of the Early Neo-Babylonian Period. A Comparative Study of 30 City-State Cultures. 2000 pp. 117-127.pdf\n",
      "The City-States of the Early Neo-Babylonian Period\n",
      "Mogens Trolle Larsen\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2000\n",
      "nan\n",
      "--------------------------------------------------\n",
      "Larsen 2000 - The Old Assyrian City-State. A Comparative Study of 30 City-State Cultures. 2000 pp. 77-87.pdf\n",
      "The Old Assyrian City-State and its Colonies\n",
      "Mogens Trolle Larsen\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2000\n",
      "nan\n",
      "--------------------------------------------------\n",
      "Larsen 2002 - The Aššur-nada Archive. PIHANS 96, 2002.pdf\n",
      "The Assur-nâdâ Archive (Old Assyrian Archives, volume 1)\n",
      "Mogens Trolle Larsen\n",
      "Leiden\n",
      "nan\n",
      "nan\n",
      "2002\n",
      "nan\n",
      "--------------------------------------------------\n",
      "Larsen 2007 - Individual and Family in Old Assyrian Society. JCS 59, 2007, pp. 93-106.pdf\n",
      "Individual and Family in Old Assyrian Society\n",
      "Mogens Trolle Larsen\n",
      "Copenhagen\n",
      "JCS\n",
      "59\n",
      "2007\n",
      "93–95\n",
      "--------------------------------------------------\n",
      "Larsen 2010 - The Archive of the Šalim-Aššur Family, Vol. 1. The First Two Generations. (A)TK 6-a, TTKY 33d-a, 2010 (preprint).pdf\n",
      "The Archive of the §alim-A$$ur Family\n",
      "Mogens Trolle Larsen\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2010\n",
      "nan\n",
      "--------------------------------------------------\n",
      "Larsen, M. T. - AKT 6a, 2010.pdf\n",
      "The Archive of the Salim-Assur Family\n",
      "Mogens Trolle Larsen\n",
      "Ankara\n",
      "Turk Tarih Kurumu Yayınları\n",
      "VI. Dizi-Sayı 33 d-a\n",
      "2010\n",
      "xvi, 585 s.\n",
      "--------------------------------------------------\n",
      "Larsen, M. T. - AKT 6b, 2013.pdf\n",
      "Kiltepe tabletleri VI-b: The Archive of the Salim-Assur family. Volume 2: Ennam- Assur\n",
      "Mogens Trolle Larsen\n",
      "Ankara\n",
      "Turk Tarih Kurumu\n",
      "nan\n",
      "2013\n",
      "xvii, 470 s.\n",
      "--------------------------------------------------\n",
      "Larsen, Mogens T. - Partnerships in the Old Assyrian Trade 18.pdf\n",
      "Partnerships in the Old Assyrian Trade\n",
      "Mogens Trolle Larsen\n",
      "nan\n",
      "Iraq\n",
      "39\n",
      "1977\n",
      "119-145\n",
      "--------------------------------------------------\n",
      "Larsen_2015_Ancient_Kanesh (2015).pdf\n",
      "Ancient Kanesh: A Merchant Colony in Bronze Age Anatolia\n",
      "Mogens Trolle Larsen\n",
      "University of Copenhagen\n",
      "Cambridge University Press\n",
      "nan\n",
      "2015\n",
      "nan\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Завантаження даних з CSV-файлу\n",
    "# thiscompteca = \"C:/Users/arecs/Мій диск (2armnot@gmail.com)/Питон/Конкурси/Old_Assyrian/\"\n",
    "csv_file_path = thiscompteca+'/data/bibliography.csv'\n",
    "df_txt = pd.read_csv(csv_file_path)\n",
    "\n",
    "\n",
    "# print(df_txt.head())  # Перші 5 строк даних\n",
    "# print(df_txt.shape)  # Dataset Shape\n",
    "print(df_txt.info())  # Dataset Information\n",
    "# print(df_txt.describe())   # Statistics\n",
    "# print(df_txt.isnull().sum())  # Missing Values\n",
    "\n",
    "num_row = 0\n",
    "for num_row in range(df_txt.shape[0]):\n",
    "    # if num_row > 10:\n",
    "    #     break\n",
    "    for num_col in range(df_txt.shape[1]):\n",
    "        if df_txt.iat[num_row, 2] == 'Mogens Trolle Larsen':\n",
    "            print(df_txt.iat[num_row, num_col])\n",
    "            if num_col == df_txt.shape[1] - 1:\n",
    "                print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4373d28-c68d-488b-ae6c-466c5fb97946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004a7dbd-57ce-46f8-9691-409be61c676e\n",
      "KIŠIB ma-nu-ba-lúm-a-šur DUMU ṣí-lá-(d)IM KIŠIB šu-(d)EN.LÍL DUMU ma-nu-ki-a-šur KIŠIB MAN-a-šur DUMU a-ta-a 0.33333 ma-na 2 GÍN KÙ.BABBAR SIG₅ i-ṣé-er PUZUR₄-a-šur DUMU a-ta-a a-lá-ḫu-um i-šu iš-tù ḫa-muš-tim ša ì-lí-dan ITU.KAM ša ke-na-tim li-mu-um e-na-sú-in a-na ITU 14 ḫa-am-ša-tim i-ša-qal šu-ma lá iš-qú-ul 1.5 GÍN.TA a-na 1 ma-na-im i-na ITU.1.KAM ṣí-ib-tám ú-ṣa-áb\n",
      "Seal of Mannum-balum-Aššur son of Ṣilli-Adad, seal of Šu-Illil son of Mannum-kī-Aššur, seal of Puzur-Aššur son of Ataya. Puzur-Aššur son of Ataya owes 22 shekels of good silver to Ali-ahum. Reckoned from the week of Ilī-dan, month of Ša-kēnātim, in the eponymy of Enna-Suen, he will pay in 14 weeks. If he has not paid in time, he will add interest at the rate 1.5 shekel per mina per month.\n",
      "--------------------------------------------------\n",
      "0064939c-59b9-4448-a63d-34612af0a1b5\n",
      "1 TÚG ša qá-tim i-tur₄-DINGIR il₅-qé\n",
      "Itūr-ilī has received one textile of ordinary quality.\n",
      "--------------------------------------------------\n",
      "0073f2c0-524c-4bbf-915a-8c1772a4fb98\n",
      "TÚG u-la i-dí-na-ku-um i-tù-ra-ma 9 GÍN KÙ.BABBAR\n",
      "... he did not give you a textile. He returned and 9 shekels of silver ...\n",
      "--------------------------------------------------\n",
      "009fb838-8038-42bc-ad34-5f795b3840ee\n",
      "KIŠIB šu-(d)EN.LÍL DUMU šu-ku-bi-im KIŠIB ṣí-lu-lu DUMU ú-ku i-nu-mì i-dí-a-bu-um a-wa-sú iq-bi-ú 10 ma-na KÙ.BABBAR a-na ša-lim-a-šùr i-dí-in um-ma šu-ut-ma i-ṣí-ba-at KÙ-pì-a li-il₅-qé\n",
      "Seal of Šu-Illil son of Šu-Kūbum, seal of Ṣilūlu son of Uku. When Iddin-abum spoke his will, he gave 10 minas ofדsilver to Šalim-Aššur. He said: He may take it from the interest on my silver.\"\"\n",
      "--------------------------------------------------\n",
      "00aa1c55-c80c-4346-a159-73ad43ab0ff7\n",
      "um-ma šu-ku-tum-ma a-na IŠTAR-lá-ma-sí ù ni-ta-aḫ-šu-šar qí-bi₄-ma mì-šu ša ta-áš-pu-ra-ni-ni um-ma a-tí-na-ma É-tum a-na lá be-tim i-tù-ar a-pu-tum a-na en-um-a-šùr i-xx-ni-ma e ší-na ga x ša lá ta-ḫa-dì-ri a-na IŠTAR-lá-ma-sí qí-bi₄-ma šu-ma a-ḫa-tí a-ta li-ba-am dì-ni-ší-im lá ta-ḫa-da-ar a-na ni-ta-aḫ-šu-šar qí-bi₄-ma TÚG-pì-ri-kà-ni ša e-zi-bu na-pí-ší-šu-nu ù ṭup-pu-ú lu ša-ṣú-ru pì-ri-kà-nu ša ma-tí ù tí-bu-lá ma-a-x iš-ta-ú-mu-ni a-dí en-um-a-šùr i-lá-kà-ni a ma-ma-an lá tù-šé-ri x GÍN KÙ.BABBAR (d)UTU-tap-pá-i ub-lá-ki-im 1 GÍN KÙ.GI ù x GÍN KÙ.BABBAR i-ku-pì-a ub-lá-ki-im\n",
      "From Šukkutum to Ištar-lamassī and Nitahšušar: Why is that you (fem. plur.) have written me, saying: The house is no longer a house.\" Urgent, to Ennam-Aššur ... Do not fear!. To Ištar-lamassī: If you are truly my sister, then encourage her. Do not fear. To Nitahšušar: Air the -textiles that I left. Also, the tablets should be guarded. The  which Mati? and Tibula ... have bought do not release (them) to anyone before Ennam-Aššur arrives. Šamaš-tappā'ī brought you x shekels of silver. Ikūn-pīya brought you 1 shekel of gold and x shekels of silver. \"\n",
      "--------------------------------------------------\n",
      "00f0d841-eb7a-46f8-86fc-bf9fd7d52cbf\n",
      "um-ma šu-ta-mu-zi e-lá-a en-um-a-šùr ù lá-ma-sí-ma a-na en-um-a-šùr ù a-lá-ḫi-im qí-bi₄-ma a-ma-la na-áš-pé-er-tí-ku-nu ra-bi-ṣa-am ni-ḫu-za-ku-nu-tí a-bi-a DUMU be-e-be ra-bi₄-iṣ-ni i-na ša-am-ší ša ra-bi-ṣú-um e-ra-ba-ni iḫ-da-ma i-zi-za-ma lu DAM.GÀR a-bi-ku-nu lu ša a-wa-tám tí-šu-a-ni ra-bi-ṣú-um i-na ša-ḫa-tí-ku-nu li-zi-iz-ma i-na KÙ.BABBAR pá-ni-ma a-šar ta-ma-ḫa-ra-ni KÙ.BABBAR ša É a-lim(ki) šu-ta-aṣ-bi-ta-ma ma-lá a-bu-ku-nu ḫa-bu-lu KÙ.BABBAR ku-un-kà-ma šé-bi-lá-nim ra-bi₄-ṣú-um iš-tí-ku-nu li-ik-nu-uk-ma KÙ.BABBAR šé-bi-lá-nim-ma li-ma-am lu nu-ša-bi ṣí-ba-at ṣí-ib-tim lá i-ma-i-da-ku-nu-tí-ma li-ba-ku-nu e im-ra-aṣ ma-lá e-ṭá-ar É a-bi₄-ku-nu ep-ša šu-ma ta-da-ga-lá-ma ṭup-pu ḫa-ru-mu-tum ú ba-ba-a-tum ru-qá-tum i-ba-ší-ú ṭup-pí ku-un-kà-ma a-na DUMU um-me-a-nim ke-nim ša ki-ma ku-nu-tí pí-iq-da-ma u₄-me-e-ku-nu ba-lu-um mì-ma-ma lá tù-ri-qá-ma lá ta-sà-ḫu-ra iš-tí ra\n",
      "From Šu-Tammuzī, Elaya, Ennam-Aššur and Lamassī to Ennam-Aššur and Ali-ahum: In accordance with your missive we have hired a attorney for you; Abiya son of Bebe is our attorney. Take care to stand by the very day the attorney arrives, and have the attorney assist you both with regard to the customers of your father and those with whom you have an argument, and of the first silver, wherever you receive it, collect the silver of the City Hall, as much as your father owes, seal the silver and send it; the attorney should seal it together with you, and then send the silver so we can satisfy the eponym. The compound interest should not grow too big for you and make you unhappy. Act so as to save your father's house. If you observe that there are certified deeds and credits outstanding on long terms, then seal the tablets, entrust them to a trustworthy affiliated trader, like yourselves, and do not extend your terms without special reasons, do not delay but set out and come together with the attorney. Here we seized (witnesses) against Šu-Kūbum and said: Did Šalim-Aššur give you 5 minas of silver out of those in your tablet?\" He refused to confirm to us the silver, what you will declare there. 0.6666 mina of silver: hire for the attorney; he received 0.3333 mina of silver here and will receive 0.3333 mina there. We gave 16.3333 shekels of silver for their disposal; 36.6666 shekels of silver, their expenses, we borrowed in a merchant-house against interest. Seal silver there and send it with the first transport so we can pay back the merchant. Also, send at least 1 or 2 minas of silver; send it so we can store 40 litres of grain before you come. Elaya says: If you are truly my brothers, you must seal the proceeds from the textile in silver and do me a favour. \"\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Завантаження даних з CSV-файлу\n",
    "# thiscompteca = \"C:/Users/arecs/Мій диск (2armnot@gmail.com)/Питон/Конкурси/Old_Assyrian/\"\n",
    "csv_file_path = thiscompteca+'/data/train.csv'\n",
    "df_txt = pd.read_csv(csv_file_path)\n",
    "num_row = 0\n",
    "for num_row in range(df_txt.shape[0]):\n",
    "    if num_row > 5:\n",
    "        break\n",
    "    for num_col in range(df_txt.shape[1]):\n",
    "        print(df_txt.iat[num_row, num_col])\n",
    "    print('-' * 50)\n",
    "\n",
    "# print(df_txt.head())  # Перші 5 строк даних\n",
    "# print(df_txt.shape)  # Dataset Shape\n",
    "# print(df_txt.info())  # Dataset Information\n",
    "# print(df_txt.describe())   # Statistics\n",
    "# print(df_txt.isnull().sum())  # Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99325c-b170-467a-acc5-793d37d4a12c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
